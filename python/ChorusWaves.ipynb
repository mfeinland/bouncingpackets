{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bouncing Packet Locator Script\n",
    "\n",
    "# Date Created: 05/15/23 (Original Script, in MATLAB)\n",
    "# Date Created: 01/03/24 (This Script)\n",
    "# Last Modified: 02/04/24\n",
    "\n",
    "# Author: Max Feinland for Blum Research Group, LASP\n",
    "\n",
    "# Inputs: start date, end date\n",
    "\n",
    "# Description: complete driver script. The user will be prompted to specify the dates they would like to see. \n",
    "# This script will then print out and plot all of the microbursts found in the specified time period.\n",
    "\n",
    "# housekeeping\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacepy.datamodel\n",
    "import spacepy.time as spt\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil.parser\n",
    "from IRBEM import MagFields\n",
    "import sampex\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as dates\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import copy\n",
    "import time\n",
    "import stopit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## O'Brien\n",
    "\n",
    "# Date created: 3/21/23 (in MATLAB)\n",
    "# or 01/04/24 in Python\n",
    "# Last modified: 02/04/24 (to fix a STUPID indexing issue, smh)\n",
    "# Author: Max Feinland for Blum Research Group, LASP\n",
    "\n",
    "# Inputs: SSD & time data, day\n",
    "\n",
    "# Outputs: starting & ending time of each microburst, plus time intervals\n",
    "\n",
    "def obrien(data):\n",
    "    N20 = data['counts'] # count rate sampled every 20 ms\n",
    "    time20 = data['time'] # time every 20 ms\n",
    "\n",
    "    # I'm sure there's a more efficient way to do this, but I don't know it\n",
    "    df = pd.DataFrame({'time': data['time'], 'counts': data['counts']})\n",
    "\n",
    "    df.set_index('time', inplace=True) # set time column as the index\n",
    "\n",
    "    # resample the dataframe to 100 ms intervals and sum the counts in each interval\n",
    "    N100 = df.resample('100ms').sum()\n",
    "\n",
    "    A500 = N100.rolling(5, center=True).mean() # 5-observation centered rolling mean (over 500 ms)\n",
    "\n",
    "    condition = np.divide((N100.counts - A500.counts), np.sqrt(1 + A500.counts)) # O'Brien et al 2003\n",
    "    \n",
    "    ns = np.argwhere(condition > 10)\n",
    "    ns = [item[0] for item in ns]\n",
    "\n",
    "    epsilon = 10; # if two flagged indices are spaced less than this distance apart, \n",
    "    # they are probably part of the same microburst\n",
    "\n",
    "    # initializing\n",
    "    starts = []\n",
    "    ends = []\n",
    "\n",
    "    dn = np.diff(ns) # difference in time between instances of the condition being true\n",
    "\n",
    "    # finding extended periods of the condition being true\n",
    "    for i in np.arange(1,len(dn)-10):\n",
    "        if dn[i] < epsilon and dn[i+1] < epsilon and dn[i-1] >= epsilon: # start condition\n",
    "            starts.append(ns[i])\n",
    "            for j in np.arange(i+1, len(dn)-1):\n",
    "                if dn[j] < epsilon and dn[j+1] >= epsilon:\n",
    "                    ends.append(ns[j]) # end condition\n",
    "                    break\n",
    "        elif dn[i] <= epsilon and i == 1: # start condition (edge case)\n",
    "            starts.append(ns[i])\n",
    "            for j in np.arange(i+1, len(dn-1)):\n",
    "                if dn[j] <= epsilon:\n",
    "                    ends.append(ns[j])\n",
    "                    break\n",
    "        elif i == len(dn): # end condition (edge case)\n",
    "            ends.append(ns[i])\n",
    "\n",
    "    if len(starts) > len(ends):\n",
    "        ends.append(starts[len(starts)-1] + 10)\n",
    "        \n",
    "    starts = [x - 2 for x in starts] # pad with 0.2 seconds \n",
    "    ends = [x + 10 for x in ends] # pad with 1 second\n",
    "\n",
    "\n",
    "    def changeCadence(time20, times100):\n",
    "        # times100 is the list of timestamps for whatever it is: starts, ends, ns\n",
    "        # times20 is the entire list of time20 for the day in question\n",
    "        try:\n",
    "            idx20 = [time20.get_loc(tstmp) for tstmp in times100] # try list comprehension first, it's faster\n",
    "        except: \n",
    "            idx20 = [] # clear and start over\n",
    "            idx20 = [np.abs((time20 - target).values).argmin() for target in times100] # if a timestamp is missing from time20,\n",
    "            # you will have to find the minimum timestamp (that is closest in time)\n",
    "        return idx20\n",
    "\n",
    "    # reverting indices to 20 ms cadence\n",
    "\n",
    "    starts20 = changeCadence(time20, N100.index[starts])\n",
    "    ends20 = changeCadence(time20, N100.index[ends])\n",
    "    ns20 = changeCadence(time20, N100.index[ns])\n",
    "\n",
    "    # yay, your output is ready!\n",
    "    d = dict(); \n",
    "    d['st'] = starts20\n",
    "    d['et'] = ends20\n",
    "    d['ns'] = ns20\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsyganenko05(tstmp):\n",
    "    # If all of the preliminary conditions checked are true, the T05 model\n",
    "    # will be called to check if the bounce period is within tolerance.\n",
    "    # Also pulls attitude data. This saves some time, since you won't need to download\n",
    "    # the attitude data otherwise.\n",
    "    a = sampex.Attitude(tstmp) # attitude data (thanks Mike!)\n",
    "    a.load()\n",
    "    omniLoc = 'C:/Users/maxim/.spacepy/data/omnidata.h5'\n",
    "    omniData = spacepy.datamodel.fromHDF5(omniLoc)\n",
    "    omniT = np.array([dateutil.parser.parse(i.decode()) for i in omniData['UTC']])\n",
    "    idx = np.where(tstmp >= omniT)[0][-1]\n",
    "    T05Keys = ['Dst', 'Pdyn', 'ByIMF', 'BzIMF', 'W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "    maginput05 = {}\n",
    "    maginput = {}\n",
    "\n",
    "    X = {}\n",
    "    a_idx = np.where(tstmp >= a['time'])[0][-1]\n",
    "    X['dateTime'] = tstmp.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    X['x1'] = a['Altitude'][a_idx]\n",
    "    X['x2'] = a['GEO_Lat'][a_idx]\n",
    "    X['x3'] = a['GEO_Long'][a_idx]\n",
    "    alpha0 = a['Pitch'][a_idx]\n",
    "    L = a['L_Shell'][a_idx]\n",
    "    MLT = a['MLT'][a_idx]\n",
    "\n",
    "    #T05 model\n",
    "    model05 = MagFields(options = [0,0,0,0,0], kext = 11)\n",
    "    for i in T05Keys:\n",
    "        maginput05[i] = float(omniData[i][idx])\n",
    "    try: \n",
    "        Tb = model05.bounce_period(X, maginput05, KE)\n",
    "    except:\n",
    "        Tb = 0\n",
    "    return Tb, X, L, alpha0, MLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bouncingPackets(so, eo, h):\n",
    "    # Date created: not sure. Sort of a Ship of Theseus thing. I originally created this in MATLAB\n",
    "    # 04/25/23, but have no idea when it was created in Python, unfortunately. Likely Jan 2024.\n",
    "    # Last modified: 02/04/2024\n",
    "    # Purpose: takes intervals specified from the O'Brien algorithm and searches for consistently-spaced,\n",
    "    # low-width-variance, isolated peaks whose bounce periods match up with the expected values.\n",
    "    \n",
    "    \n",
    "    # Intializing variables\n",
    "    pksi = []\n",
    "    st = []\n",
    "    et = []\n",
    "    \n",
    "    per = []\n",
    "    L = []\n",
    "    alpha0 = []\n",
    "    X = []\n",
    "    MLT = []\n",
    "    TbT05 = []\n",
    "    \n",
    "    # load in HILT data\n",
    "    t = h.times\n",
    "    rate = h.counts\n",
    "    with stopit.ThreadingTimeout(30) as context_manager:\n",
    "        for i in range(len(so)):\n",
    "            interval = rate[so[i]:eo[i]] # define just one chunk of the rate data, taken from O'Brien\n",
    "            maxdis = max(interval) - min(interval) # use to generate prominence requirement\n",
    "\n",
    "            # finding peaks with a high enough prominence\n",
    "            [pks, _] = find_peaks(interval, prominence=0.25*maxdis, distance=3)\n",
    "            npks = list(so[i] + loc for loc in pks)\n",
    "            pksi.extend(npks)\n",
    "\n",
    "            loc = pd.to_datetime(t[npks])\n",
    "\n",
    "            dloc = [loc[i + 1] - loc[i] for i in range(len(loc) - 1)]\n",
    "            dloc = [x.total_seconds() for x in dloc]\n",
    "            ddloc = np.diff(dloc) # change in peak spacing; must be sufficiently small, i.e.\n",
    "            # the peaks must be very regularly spaced.\n",
    "\n",
    "            # Schulz and Lanzerotti Bounce period equation (stolen from Mike)\n",
    "            Tsl = lambda L, alpha0, v: 4*6.371E6*np.divide(L, v) * \\\n",
    "                   (1.3802 - 0.3198*(np.sin(np.deg2rad(alpha0)) + \\\n",
    "                   np.sqrt(np.sin(np.deg2rad(alpha0)))))\n",
    "            beta = lambda Ek: np.sqrt(1-((Ek/511)+1)**(-2)) # Lorentz factor, I think\n",
    "            c = 3.0E8 # m/s; true for the observable universe, presumably\n",
    "            KE = 1000 # keV; true of all particles observed at SAMPEX\n",
    "\n",
    "\n",
    "            if len(ddloc) >= 2:\n",
    "                threshold = 0.05 # lowest allowable change in period\n",
    "\n",
    "                indices = np.where(np.convolve(np.abs(ddloc) < threshold, \\\n",
    "                                               np.ones(2), mode='valid') == 2)[0]\n",
    "\n",
    "                if len(indices) == 1: # if there is exactly one microburst\n",
    "                    tstmp_start = loc[indices[0]] - pd.Timedelta(seconds=0.2)\n",
    "                    tstmp_final = loc[indices[0]+3] + pd.Timedelta(seconds=0.2)\n",
    "                    et.extend(np.where(t == tstmp_final)[0])\n",
    "                    st.extend(np.where(t == tstmp_start)[0])\n",
    "                elif len(ddloc) >= 4 and len(indices) > 1: # splits up sequences\n",
    "                    for j in range(len(indices)-1):\n",
    "                        # if you are looking at the first index and there is not a jump, that is a start time\n",
    "                        if j == 0 and indices[j + 1] - indices[j] == 1:\n",
    "                            tstmp_start = loc[indices[j]] - pd.Timedelta(seconds=0.2)\n",
    "                            st.extend(np.where(t == tstmp_start)[0])\n",
    "                        elif j == 0: # otherwise, nothing happens!\n",
    "                            pass\n",
    "                        # if previously, you were not in a consecutive streak, but now you are, that is a start time\n",
    "                        elif indices[j+1] - indices[j] == 1 and indices[j] - indices[j-1] > 1:\n",
    "                            tstmp_start = loc[indices[j]] - pd.Timedelta(seconds=0.2)\n",
    "                            st.extend(np.where(t == tstmp_start)[0])\n",
    "                        # if previously, you were in a consecutive streak, but now you are not, that is an endtime\n",
    "                        elif indices[j+1] - indices[j] > 1 and indices[j] - indices[j-1] == 1:\n",
    "                            tstmp_final = loc[indices[j]+3] + pd.Timedelta(seconds=0.2)\n",
    "                            et.extend(np.where(t == tstmp_final)[0])\n",
    "\n",
    "                    # end condition if the previous one wasn't met\n",
    "                    if len(st) > len(et):\n",
    "                        tstmp_final = loc[indices[j]+3] + pd.Timedelta(seconds=0.2)\n",
    "                        et.extend(np.where(t == tstmp_final)[0])\n",
    "\n",
    "        # The variables st and et contain all intervals that satisfy the strict bounce period condition.\n",
    "        # Now we will check the other conditions.\n",
    "    if context_manager.state == context_manager.EXECUTED:\n",
    "        st = np.sort(st)\n",
    "        et = np.sort(et)\n",
    "    \n",
    "    elif context_manager.state == context_manager.TIMED_OUT:\n",
    "        st = []\n",
    "        et = []\n",
    "        print(\"Timed out execution. Skipping this day.\")\n",
    "\n",
    "    final_st = []\n",
    "    final_et = []\n",
    "    finalpksi = []\n",
    "\n",
    "    for k in range(len(st)):\n",
    "        print('st =', k)\n",
    "        ok_range_for_this_index = np.arange(st[k], et[k]+1).tolist()\n",
    "        these_pk_indices = [index for index, value in enumerate(pksi) if value in ok_range_for_this_index]\n",
    "        relative_pks = [pksi[x]-st[k] for x in these_pk_indices]\n",
    "        current_per = np.mean(np.diff(relative_pks))*0.02 # mean period\n",
    "        \n",
    "        interval = rate[st[k]:et[k]]\n",
    "        \n",
    "        try:\n",
    "            widths = peak_widths(interval, relative_pks, rel_height=0.5)\n",
    "            lowvarw = np.std(widths[0]) <= 0.4*np.mean(widths[0])\n",
    "                    # Needed to make the condition \"isol\"\n",
    "            desired_starttime = t[st[k]] - pd.Timedelta(seconds=3.5)\n",
    "            idxs = np.abs(np.array(t, dtype='datetime64') - np.datetime64(desired_starttime)).argmin()\n",
    "            interval2_start = idxs\n",
    "\n",
    "            desired_endtime = t[et[k]] + pd.Timedelta(seconds=3.5)\n",
    "            idxe = np.abs(np.array(t, dtype='datetime64') - np.datetime64(desired_endtime)).argmin()\n",
    "            interval2_end = idxe\n",
    "            interval2 = rate[interval2_start:interval2_end]\n",
    "\n",
    "            interval = rate[st[k]:et[k]]\n",
    "            maxdis = max(interval) - min(interval)\n",
    "            [loc2, _] = find_peaks(interval2, prominence=0.25*maxdis, distance=3)\n",
    "            intermediate_list = []\n",
    "            intermediate_list = (st[k]-175 + loc2).tolist()\n",
    "            all_pks_for_interval = [pksi[x] for x in these_pk_indices]\n",
    "            for item in all_pks_for_interval:\n",
    "                if item in intermediate_list:\n",
    "                    intermediate_list.remove(item)\n",
    "\n",
    "            isol = len(intermediate_list) < 10\n",
    "            unq = len(np.unique(rate[st[k]:et[k]])) > 10\n",
    "\n",
    "            passesMostConditions = isol and unq and lowvarw\n",
    "        except:\n",
    "            passesMostConditions = False\n",
    "\n",
    "        # This is split up into two cases because the TbT05 calculation takes FOREVER to run.\n",
    "        # So, the first three conditions must be true before the last one will be checked.\n",
    "        if passesMostConditions == True:\n",
    "            print('Calling Tsyganenko 2005 model. This may take a while; please be patient.')\n",
    "            [Tb, current_X, current_L, current_alpha0, current_MLT] = tsyganenko05(t[st[k]]) \n",
    "            okper = (np.abs(current_per - Tb) < 0.15 or np.abs(current_per - Tb/2) < 0.1) and Tb > 0\n",
    "            if okper == True:\n",
    "                per.append(current_per)\n",
    "                L.append(current_L)\n",
    "                alpha0.append(current_alpha0)\n",
    "                X.append(current_X)\n",
    "                MLT.append(current_MLT)\n",
    "                TbT05.append(Tb)\n",
    "                final_st.append(st[k])\n",
    "                final_et.append(et[k])\n",
    "                finalpksi.append(all_pks_for_interval)\n",
    "    \n",
    "    data = pd.DataFrame({'t': [h.times[x] for x in final_st], 'per': per, 'tb': TbT05, 'L': L, \n",
    "                         'alpha0': alpha0, 'MLT': MLT})\n",
    "    return final_st, final_et, finalpksi, data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the ChorusWaves search script.\n",
      "Coded by Max Feinland for Blum Research Group, 2023-2024.\n",
      "Enter a start date formatted as \"YYYY, MM, DD\":1996, 10, 22\n",
      "Enter an end date, or enter the number of days as an integer (from 1 to 30): 3\n",
      "\n",
      "Collecting data for October 22, 1996 ...\n",
      "Downloaded hhrr1996296.txt.zip.\n",
      "Running O'Brien algorithm...\n",
      "Searching for bouncing packets...\n",
      "st = 0\n",
      "Calling Tsyganenko 2005 model. This may take a while; please be patient.\n",
      "Downloading PSSet_6sec_1996295_1996321.txt.zip: |####################| 100%\n",
      "st = 1\n",
      "st = 2\n",
      "st = 3\n",
      "st = 4\n",
      "Calling Tsyganenko 2005 model. This may take a while; please be patient.\n",
      "st = 5\n",
      "No intervals found.\n",
      "\n",
      "Collecting data for October 23, 1996 ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to the ChorusWaves search script.\", flush=True)\n",
    "print(\"Coded by Max Feinland for Blum Research Group, 2023-2024.\")\n",
    "\n",
    "if 'data' in globals():\n",
    "    keepvar = input(\"Looks like you ran this script recently. Want to keep that data in the workspace? (y/n) \")\n",
    "    if keepvar.lower() == \"y\":\n",
    "        data_old = data\n",
    "    else:\n",
    "        del(data)\n",
    "\n",
    "if 'first_day' in globals():\n",
    "    fdo = first_day_d\n",
    "    ldo = last_day_d\n",
    "    f_fd = fdo.strftime(\"%B %d, %Y\")\n",
    "    f_ld = ldo.strftime(\"%B %d, %Y\")\n",
    "    if f_fd == f_ld:\n",
    "        print(f\"The most recently queried date was {f_fd}.\", flush=True)\n",
    "    else:\n",
    "        print(f\"The most recently queried dates were {f_fd} to {f_ld}.\", flush=True)\n",
    "    print(\"Press o to set the first date as 1 after the last date of the last query.\")\n",
    "    first_day = input(\"Enter a start date formatted as \\\"YYYY, MM, DD\\\", or press r for the most recently queried dates: \")\n",
    "else:\n",
    "    first_day = input(\"Enter a start date formatted as \\\"YYYY, MM, DD\\\": \" )\n",
    "\n",
    "if first_day == \"r\":\n",
    "    try:\n",
    "        first_day_d = fdo\n",
    "        last_day_d = ldo\n",
    "    except:\n",
    "        print(\"Looks like you cleared your old dates; can't use that command, sorry.\")\n",
    "elif first_day == \"o\":\n",
    "    first_day_d = ldo + timedelta(days=1)\n",
    "else:\n",
    "    first_day = first_day.split(\", \")\n",
    "    first_day_d = datetime(int(first_day[0]), int(first_day[1]), int(first_day[2]))\n",
    "    last_day = input(\"Enter an end date, or enter the number of days as an integer (from 1 to 30): \")\n",
    "    try:\n",
    "        last_day = int(last_day)\n",
    "        if last_day in np.arange(1, 31):\n",
    "            last_day_d = first_day_d + timedelta(days = last_day - 1)\n",
    "        else:\n",
    "            print(\"Number of days not allowed. Please try again.\")\n",
    "            print(\"Zero days is not allowed for obvious reasons, and more than 30 are not recommended due to processing time.\")\n",
    "    except:\n",
    "        try:\n",
    "            last_day = last_day.split(\", \")\n",
    "            last_day_d = datetime(int(last_day[0]), int(last_day[1]), int(last_day[2]))\n",
    "        except:\n",
    "            print(\"Unrecognized command; could not execute.\")\n",
    "\n",
    "date_list = [first_day_d + timedelta(days=i) for i in range((last_day_d - first_day_d).days + 1)]\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for day in date_list:\n",
    "    formatted_date = day.strftime(\"%B %d, %Y\")\n",
    "    print(f\"\\nCollecting data for {formatted_date} ...\")\n",
    "    h = sampex.HILT(day) # count rate data (thanks Mike!)\n",
    "    h.load()\n",
    "    print(\"Running O'Brien algorithm...\")\n",
    "    d = obrien(h) # call O'Brien function\n",
    "\n",
    "    so = d['st']\n",
    "    eo = d['et']\n",
    "    ns = d['ns']\n",
    "\n",
    "    print(\"Searching for bouncing packets...\")\n",
    "    [st, et, pksi, this_data] = bouncingPackets(so, eo, h)\n",
    "    data = pd.concat([data, this_data], ignore_index=True)\n",
    "\n",
    "    if len(st) == 0:\n",
    "        print(\"No intervals found.\")\n",
    "    elif len(st) == 1:\n",
    "        print(\"1 interval found. Plotting now.\")\n",
    "    else:\n",
    "        print(len(st), \"intervals were found. Plotting now.\")\n",
    "\n",
    "    for j in range(len(st)):\n",
    "        fig = plt.figure(j)\n",
    "        ax = fig.add_subplot()\n",
    "        plt.grid(True)\n",
    "\n",
    "        ax.plot(h.times[st[j]:et[j]], h.counts[st[j]:et[j]])\n",
    "        ax.plot(h.times[pksi[j]], h.counts[pksi[j]], marker='d')\n",
    "        ax.xaxis.set_major_formatter(dates.DateFormatter('%H:%M:%S.%f')) \n",
    "        ax.set_xlabel('Time (UTC)')\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.set_ylabel('Counts (#/20 ms)')\n",
    "        ax.tick_params(colors='white', which='both')\n",
    "        ax.set_title('Bouncing Packets on ' + h.times[st[j]].strftime('%Y-%m-%d'))\n",
    "        ax.title.set_color('white')\n",
    "        plt.show()\n",
    "#     except:\n",
    "#         print(\"No data available for this day; skipping.\")\n",
    "\n",
    "print(data)\n",
    "save_yn = input('Would you like to save this data? (y/n) ')\n",
    "if save_yn.lower() == 'y':\n",
    "    filename = input('Provide a name for this file: ')\n",
    "    data.to_csv(filename, sep=',', index=False, encoding='utf-8')\n",
    "    \n",
    "print('Script complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
